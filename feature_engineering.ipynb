{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxyrong/w281-project/blob/main/feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmww0qJycIFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636fe362-a636-49d8-bff4-04c7a968254e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otWK_RlFkmNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2eed37-cc49-4dac-a674-1eb0ada5fc95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 371 µs (started: 2023-12-11 06:46:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8ewb_JS-IB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1aa1df-3a1c-4d43-d967-07a2a7297d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.02 s (started: 2023-12-11 06:46:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from numpy import fft\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage.feature import hog, canny\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "import cv2\n",
        "from PIL import Image, ImageStat\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18nRczIcTSZ"
      },
      "source": [
        "# Data Loading & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQrSGRfZ9FFS",
        "outputId": "6004a26a-00ef-4687-9c4c-267187e57b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.44 ms (started: 2023-12-11 06:46:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def load_dataset(datapath):\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for folder in os.listdir(datapath):\n",
        "      files = glob(pathname= str(datapath + folder + \"/*.jpg\"))\n",
        "      df = pd.concat([df, pd.DataFrame( { \"filename\": files ,\n",
        "                                          \"category\": folder } ) ])\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    df[\"image\"] = None\n",
        "    df[\"gray_image\"] = None\n",
        "    df[\"hsv_image\"] = None\n",
        "    df[\"resolution\"] = None\n",
        "    for idx, row in df.iterrows():\n",
        "      img = Image.open(row[\"filename\"])\n",
        "      df.at[idx, \"image\"] = np.array(img, dtype=np.float32).flatten() # (150, 150, 3)\n",
        "      df.at[idx, \"gray_image\"] = np.array(img.convert(\"L\")).flatten() # (150, 150)\n",
        "      df.at[idx, \"hsv_image\"] = np.array(img.convert(\"HSV\")).flatten() # (150, 150, 3)\n",
        "      df.at[idx, \"resolution\"]  = img.size\n",
        "\n",
        "    df = df[df[\"resolution\"] == (150, 150)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# load directly\n",
        "# train_path = \"drive/MyDrive/github/w281-project-me/dataset/seg_train/seg_train/\"\n",
        "# test_path = \"drive/MyDrive/github/w281-project-me/dataset/seg_test/seg_test/\"\n",
        "# train_df = load_dataset(train_path)\n",
        "# test_df = load_dataset(test_path)\n",
        "\n",
        "# save to parquet locally\n",
        "# train_df.to_parquet(\"drive/MyDrive/github/w281-project-me/dataset/train_df_3.parquet.gzip\",compression=\"gzip\")\n",
        "# test_df.to_parquet(\"drive/MyDrive/github/w281-project-me/dataset/test_df.parquet.gzip\",compression=\"gzip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_parquet(datapath):\n",
        "    df = pd.read_parquet(datapath)\n",
        "    for idx, row in df.iterrows():\n",
        "      df.at[idx, \"image\"] = df.at[idx, \"image\"].reshape((150, 150, 3)).astype(\"uint8\")\n",
        "      df.at[idx, \"gray_image\"] = df.at[idx, \"gray_image\"].reshape((150, 150)).astype(\"uint8\")\n",
        "      df.at[idx, \"hsv_image\"] = df.at[idx, \"hsv_image\"].reshape((150, 150, 3)).astype(\"uint8\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_train(frac=1):\n",
        "    train_1 = load_dataset_parquet(\"drive/MyDrive/github/w281-project-me/dataset/train_df_1.parquet.gzip\")\n",
        "    train_2 = load_dataset_parquet(\"drive/MyDrive/github/w281-project-me/dataset/train_df_2.parquet.gzip\")\n",
        "    train_3 = load_dataset_parquet(\"drive/MyDrive/github/w281-project-me/dataset/train_df_3.parquet.gzip\")\n",
        "\n",
        "    train_df = pd.concat([train_1, train_2, train_3], ignore_index=True)\n",
        "\n",
        "    train_df = train_df.sample(frac=frac)\n",
        "    return train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7qCB9dG7A8z",
        "outputId": "e8f3bdb5-7463-469b-9840-031768b4cf5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 818 µs (started: 2023-12-11 06:46:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load parquet from local\n",
        "test_path = \"drive/MyDrive/github/w281-project-me/dataset/test_df.parquet.gzip\"\n",
        "train_df = load_train()\n",
        "test_df = load_dataset_parquet(test_path)\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP9EhfYhQmpG",
        "outputId": "5b70e843-34d4-4b57-f73f-702ed7c746bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 55.3 s (started: 2023-12-11 06:46:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv_5gkYIw_9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a9754b-28a5-4e93-a39c-e3519a467abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "buildings    2190\n",
            "forest       2263\n",
            "glacier      2387\n",
            "mountain     2495\n",
            "sea          2270\n",
            "street       2381\n",
            "Name: image, dtype: int64\n",
            "category\n",
            "buildings    437\n",
            "forest       473\n",
            "glacier      549\n",
            "mountain     523\n",
            "sea          510\n",
            "street       501\n",
            "Name: image, dtype: int64\n",
            "time: 7.48 ms (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.groupby(\"category\")[\"image\"].count())\n",
        "print(test_df.groupby(\"category\")[\"image\"].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNVPk69scZOm"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## RGB feature\n",
        "def add_rgb_feature(row):\n",
        "    r, g, b = np.mean(train_df.iloc[0][\"image\"], axis=(0, 1))\n",
        "    row[\"mean_r\"] = r\n",
        "    row[\"mean_g\"] = g\n",
        "    row[\"mean_b\"] = b\n",
        "\n",
        "    return row"
      ],
      "metadata": {
        "id": "-OkBSa6NGjFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3deccf-eeb2-4edc-f339-9820ceef7264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 464 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## HSV feature\n",
        "def add_hsv_feature(row):\n",
        "    image = Image.fromarray(row[\"hsv_image\"].astype(\"uint8\"))\n",
        "    hsv_stats = ImageStat.Stat(image)\n",
        "\n",
        "    row[\"mean_h\"] = hsv_stats.mean[0]\n",
        "    row[\"mean_s\"] = hsv_stats.mean[1]\n",
        "    row[\"mean_v\"] = hsv_stats.mean[2]\n",
        "\n",
        "    row[\"stddev_h\"] = hsv_stats.stddev[0]\n",
        "    row[\"stddev_s\"] = hsv_stats.stddev[1]\n",
        "    row[\"stddev_v\"] = hsv_stats.stddev[2]\n",
        "\n",
        "    row[\"hsv_histogram\"] = np.array(image.histogram())\n",
        "\n",
        "    return row"
      ],
      "metadata": {
        "id": "vYboztCiQ3BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aec944d-8d6d-49ca-cebb-847e67114e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 566 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMfB3c79LG-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78730528-da5e-44ac-c710-c1474a2aba47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 484 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "## HOG feature\n",
        "def add_hog_feature(row):\n",
        "  row[\"hog_feature\"], row[\"hog_image\"] = hog(row[\"image\"],\n",
        "                                             orientations=8,\n",
        "                                             pixels_per_cell=(15, 15),\n",
        "                                             cells_per_block=(1, 1),\n",
        "                                             visualize=True,\n",
        "                                             channel_axis=-1)\n",
        "\n",
        "  return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF3sIPSMvT6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddefa830-5fc6-4fab-9492-12133f52a8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 545 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "## Canny Edge Detection\n",
        "def add_canny_feature(row):\n",
        "  row[\"canny_feature\"] = canny(row[\"gray_image\"], sigma=2).flatten()\n",
        "  return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R21I8ll6latX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d595c57b-194a-4b0d-8f48-cba176b9d037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 571 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def add_fourier_feature(row):\n",
        "  image = row[\"gray_image\"]\n",
        "  ydim = image.shape[0]\n",
        "  xdim = image.shape[1]\n",
        "  win = np.outer(np.hanning(ydim), np.hanning(xdim))\n",
        "  win = win/np.mean(win)\n",
        "  fourier = fft.fftshift(fft.fft2(image * win))\n",
        "  Fmag = np.abs(fourier)\n",
        "  row[\"fourier_feature\"] = np.log(Fmag).flatten()\n",
        "  return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-76NalrvX--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a4230e-4c1d-4d51-ba84-62d328e7a0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 234 µs (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "## HED Edge Detection\n",
        "## https://github.com/s9xie/hed\n",
        "\n",
        "# def blob_batch_processing(original_images):\n",
        "#   images = copy.deepcopy(original_images)\n",
        "#   images = images.apply(lambda x: cv2.resize(x, (299, 299)))\n",
        "#   images = np.array(images)\n",
        "#   blob = cv2.dnn.blobFromImages(images, scalefactor=1, size=(299, 299),\n",
        "#     mean=(105, 117, 123), #MODEL MEAN VALUE\n",
        "#     swapRB=True, crop=False)\n",
        "#   blob = list(blob)\n",
        "#   blob = [b[np.newaxis, :]for b in blob]\n",
        "#   return blob\n",
        "\n",
        "# # The pre-trained model that OpenCV uses has been trained in Caffe framework\n",
        "# proto_path = \"drive/MyDrive/github/w281-project-me/third_party/HED/deploy.prototxt\"\n",
        "# model_path = \"drive/MyDrive/github/w281-project-me/third_party/HED/hed_pretrained_bsds.caffemodel\"\n",
        "# net = cv2.dnn.readNetFromCaffe(proto_path, model_path)\n",
        "\n",
        "# def add_HED_feature(row):\n",
        "#   net.setInput(row[\"blob\"])\n",
        "#   hed = net.forward()\n",
        "#   hed = cv2.resize(np.squeeze(hed), (150, 150))\n",
        "#   hed = cv2.cvtColor(hed, cv2.COLOR_GRAY2BGR)\n",
        "#   hed = (255 * hed).astype(\"uint8\")\n",
        "#   row[\"hed\"] = hed.flatten()\n",
        "#   return row\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bag_of_visual_word_feature(train_df, test_df):\n",
        "    extractor = cv2.xfeatures2d.SIFT_create()\n",
        "    k = 200 # number of visual words\n",
        "\n",
        "    def add_sift(row):\n",
        "        img = row[\"gray_image\"]\n",
        "        img_keypoints, img_descriptors = extractor.detectAndCompute(img, None)\n",
        "        row[\"keypoint\"] = img_keypoints\n",
        "        row[\"descriptor\"] = img_descriptors\n",
        "        return row\n",
        "\n",
        "    def add_visual_words(row):\n",
        "        img_descriptors = row[\"descriptor\"]\n",
        "        img_visual_words = []\n",
        "        if img_descriptors is not None:\n",
        "          img_visual_words, distance = vq(img_descriptors, codebook)\n",
        "          row[\"visual_word\"] = img_visual_words\n",
        "\n",
        "        img_frequency_vector = np.zeros(k)\n",
        "        for word in img_visual_words:\n",
        "            img_frequency_vector[word] += 1\n",
        "        row[\"frequency_vector\"] = img_frequency_vector\n",
        "        return row\n",
        "\n",
        "    # creating codebook for visual words\n",
        "    train_df = train_df.apply(add_sift, axis=1)\n",
        "    test_df = test_df.apply(add_sift, axis=1)\n",
        "\n",
        "    sample_index = train_df[train_df[\"descriptor\"].notna()].sample(frac=0.2).index\n",
        "    all_descriptors = np.vstack(train_df.loc[sample_index][\"descriptor\"].to_numpy())\n",
        "    codebook, variance = kmeans(all_descriptors, k, 1)\n",
        "\n",
        "    # compute tfidf\n",
        "    train_df = train_df.apply(add_visual_words, axis=1)\n",
        "    test_df = test_df.apply(add_visual_words, axis=1)\n",
        "\n",
        "    train_frequency_vectors = np.vstack(train_df[\"frequency_vector\"])\n",
        "    test_frequency_vectors = np.vstack(test_df[\"frequency_vector\"])\n",
        "    idf = np.log(len(train_df) / np.sum(train_frequency_vectors > 0, axis=0))\n",
        "    train_tfidf =  train_frequency_vectors * idf\n",
        "    test_tfidf = test_frequency_vectors * idf\n",
        "    train_df[\"bag_of_visual_words\"] = list(train_tfidf)\n",
        "    test_df[\"bag_of_visual_words\"] = list(test_tfidf)\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "T8nrqGgcRc_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ceb8bf-6098-48c8-8519-15139fa1bd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.09 ms (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RGB\n",
        "train_df = train_df.apply(add_rgb_feature, axis=1) # 52 sec\n",
        "test_df = test_df.apply(add_rgb_feature, axis=1) # 13 sec\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imv3nAysjVHg",
        "outputId": "a11be06a-7503-46cd-9732-ee46c3dd9d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 40.9 s (started: 2023-12-11 06:47:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HSV (768, 0)\n",
        "train_df = train_df.apply(add_hsv_feature, axis=1) # 52 sec\n",
        "test_df = test_df.apply(add_hsv_feature, axis=1) # 13 sec\n",
        "\n",
        "#filter out black & white images\n",
        "train_df = train_df[train_df[\"mean_h\"] > 5]\n",
        "test_df = test_df[test_df[\"mean_h\"] > 5]\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "nOUenswGQhpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9c922e-25bc-4a67-e9a8-0dbd769d9e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 16s (started: 2023-12-11 06:47:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16 (8192, 0)\n",
        "vgg_model = VGG16(include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "train_df[\"vgg_input\"] = train_df[\"image\"].apply(preprocess_input)\n",
        "train_df[\"vgg16_feature\"] = list(vgg_model.predict(np.stack(train_df[\"vgg_input\"].to_numpy()),\n",
        "                                                 verbose=False).reshape(len(train_df), -1))\n",
        "\n",
        "train_df.drop(columns=['vgg_input'], inplace=True)\n",
        "gc.collect()\n",
        "\n",
        "test_df[\"vgg_input\"] = test_df[\"image\"].apply(preprocess_input)\n",
        "test_df[\"vgg16_feature\"] = list(vgg_model.predict(np.stack(test_df[\"vgg_input\"].to_numpy()),\n",
        "                                                 verbose=False).reshape(len(test_df), -1))\n",
        "test_df.drop(columns=['vgg_input'], inplace=True)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "yNB7Lg7517jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbd56aa-3e06-4721-e0ae-111d8d5614c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "643"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 52s (started: 2023-12-11 07:03:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HOG: shape = (800, 0)\n",
        "train_df = train_df.apply(add_hog_feature, axis=1)  # 211 sec\n",
        "test_df = test_df.apply(add_hog_feature, axis=1) # 44 sec\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "V_64mC3YS_fB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71af7812-33c2-4ebb-eb6b-779d90bb28de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5min 6s (started: 2023-12-11 07:21:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Canny: shape = (150, 150) Not using due to low performance\n",
        "train_df = train_df.apply(add_canny_feature, axis=1) # 64 sec\n",
        "test_df = test_df.apply(add_canny_feature, axis=1) # 13 sec\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "yi73NHhbTCYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04ca8f8-424d-4b7a-a515-e75a86af2c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 47s (started: 2023-12-11 07:26:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HED shape = (150, 150, 3) Not using due to long runtime\n",
        "# train_df[\"blob\"] = blob_batch_processing(train_df[\"image\"])\n",
        "# train_df = train_df.apply(add_HED_feature, axis=1)\n",
        "# test_df = test_df.apply(add_HED_feature, axis=1)"
      ],
      "metadata": {
        "id": "I5-2jJl7TGuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8a7599-6a1e-4da7-9082-f0633d964ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 241 µs (started: 2023-12-11 07:27:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fourier: shape = (150, 150)\n",
        "train_df = train_df.apply(add_fourier_feature, axis=1)\n",
        "test_df = test_df.apply(add_fourier_feature, axis=1)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "1W89-a6RTMl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a4070d-b760-4d2f-a31e-415514dccbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 38.8 s (started: 2023-12-11 07:27:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd3xEz8avKeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034849ff-cf12-40fa-e4bd-dda80123f121"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4min 37s (started: 2023-12-11 07:28:37 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# bag of visual words\n",
        "train_df, test_df = add_bag_of_visual_word_feature(train_df, test_df)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DJOlPgjcOyX"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEtjDFnacLxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28708073-5348-4cc2-a462-101f68ce235f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.2 ms (started: 2023-12-11 07:33:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def pca_analysis(df, feature_dimensions):\n",
        "    explained_variance_dict = {}\n",
        "\n",
        "    for feature, num_component in feature_dimensions.items():\n",
        "        print(feature)\n",
        "        feature_vector = np.stack(df[feature].to_numpy())\n",
        "\n",
        "        explained_variance = []\n",
        "        max_components = min(num_component, len(df))\n",
        "\n",
        "        for components in range(5, max_components + 1, 5):\n",
        "            pca = PCA(n_components=components)\n",
        "            pca.fit(feature_vector)\n",
        "            total_variance = np.sum(pca.explained_variance_ratio_)\n",
        "            explained_variance.append(total_variance)\n",
        "\n",
        "        explained_variance_dict[feature] = explained_variance\n",
        "\n",
        "    return explained_variance_dict\n",
        "\n",
        "\n",
        "def pca_analysis_plot(explained_variance_dict):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for feature, variances in explained_variance_dict.items():\n",
        "        plt.plot([i * 5 for i in range(1, len(variances) + 1)],\n",
        "                 variances,\n",
        "                 label=feature)\n",
        "\n",
        "    plt.title(\"Explained Variance by Feature from PCA Analysis\")\n",
        "    plt.xlabel(\"Component Number\")\n",
        "    plt.ylabel(\"Explained Variance\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpQKlZlCdQVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37ff7d9-d208-48f2-a2d7-5d804b19d766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 409 µs (started: 2023-12-11 07:33:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "feature_dimensions = {\n",
        "    \"hsv_histogram\" : 768,\n",
        "    \"hog_feature\": 800,\n",
        "    \"canny_feature\": 22500,\n",
        "    \"vgg16_feature\": 8192,\n",
        "    \"fourier_feature\": 22500,\n",
        "    \"bag_of_visual_words\": 200\n",
        "}\n",
        "\n",
        "# explained_variance_dict = pca_analysis(train_df.sample(700),\n",
        "                                      #  feature_dimensions)\n",
        "\n",
        "# pca_analysis_plot(explained_variance_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_pca_components = {\n",
        "    \"hsv_histogram\" : 50,\n",
        "    \"hog_feature\": 100,\n",
        "    \"vgg16_feature\": 200,\n",
        "    \"fourier_feature\": 25,\n",
        "    \"bag_of_visual_words\": 40\n",
        "}\n",
        "\n",
        "pca_features = [f\"pca_{feature}\" for feature in feature_pca_components.keys()]\n",
        "print(pca_features)"
      ],
      "metadata": {
        "id": "GYBtEIWUCZdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4cc9ff-4c3b-425b-855c-95d1e83b6ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pca_hsv_histogram', 'pca_hog_feature', 'pca_vgg16_feature', 'pca_fourier_feature', 'pca_bag_of_visual_words']\n",
            "time: 620 µs (started: 2023-12-11 07:33:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtIFkgM_sD5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27819097-7543-4cf1-b6a2-a485618cd343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hsv_histogram 0.8734238434244337\n",
            "hog_feature 0.6916298380552427\n",
            "vgg16_feature 0.570367\n",
            "fourier_feature 0.4756601873218522\n",
            "bag_of_visual_words 0.7636443479635329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 37.9 s (started: 2023-12-11 07:33:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def apply_pca(train_df, test_df, feature_pca_components):\n",
        "    for feature, num_component in feature_pca_components.items():\n",
        "        pca = PCA(n_components=num_component)\n",
        "        pca.fit(np.stack(train_df[feature].to_numpy()))\n",
        "        train_df[f\"pca_{feature}\"] = list(pca.transform(np.stack(train_df[feature].to_numpy())))\n",
        "        print(feature, np.sum(pca.explained_variance_ratio_))\n",
        "        test_df[f\"pca_{feature}\"] = list(pca.transform(np.stack(test_df[feature].to_numpy())))\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = apply_pca(train_df, test_df, feature_pca_components)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_path = \"drive/MyDrive/github/w281-project-me/dataset/train_features_full.parquet.gzip\"\n",
        "test_features_path = \"drive/MyDrive/github/w281-project-me/dataset/test_features_full.parquet.gzip\"\n",
        "\n",
        "features = [\"mean_r\", \"mean_g\", \"mean_b\", \"mean_h\", \"mean_s\", \"mean_v\", \"stddev_h\", \"stddev_s\", \"stddev_v\",\n",
        "            \"pca_hsv_histogram\", \"pca_hog_feature\", \"pca_vgg16_feature\",\n",
        "            \"pca_fourier_feature\", \"pca_bag_of_visual_words\"]\n",
        "\n",
        "train_features_df = train_df[features + [\"category\", \"image\"]].copy()\n",
        "for idx, row in train_features_df.iterrows():\n",
        "  train_features_df.at[idx, \"image\"] = train_features_df.at[idx, \"image\"].flatten()\n",
        "train_features_df.to_parquet(train_features_path, compression=\"gzip\")\n",
        "\n",
        "test_features_df = test_df[features + [\"category\", \"image\"]]\n",
        "for idx, row in test_features_df.iterrows():\n",
        "    test_features_df.at[idx, \"image\"] = test_features_df.at[idx, \"image\"].flatten()\n",
        "test_features_df.to_parquet(test_features_path, compression=\"gzip\")"
      ],
      "metadata": {
        "id": "spFGVk8yzxr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6399ed04-0c15-4653-a64b-1477ceb50b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 35s (started: 2023-12-11 07:37:05 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}